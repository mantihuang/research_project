---
title: "Research Proposal"
author: "Manting Huang"

execute:
  echo : false
  message: false
  warning: false
  
bibliography: references.bib
---

> **Abstract.**  This research project investigates the effects of unanticipated government spending shocks on output, real exchange rate, and consumption, particularly in the context of the Australian economy. Utilizing quarterly data and the SVAR model, the study captures the dynamic relationships among the endogenous variables. The model estimates impulse response functions (IRFs) and forecast error variance decomposition (FEVDs) for each endogenous variable, allowing for the examination of the dynamic responses of variables and quantification of forecast error variances attributable to the shocks. 
>
> **Keywords.** Government spending shock, exchange rate,impulse responses

Please note that the website https://www.rba.gov.au/statistics/tables/ may sometimes be unstable and unable to load. Therefore, you may encounter errors such as "Could not read HTML at https://www.rba.gov.au/statistics/tables/" when using read_rba() in R.



# 1. The question objective, and motivation

## Objective
The research project aims to model the effect of government spending shocks on output, real exchange rate and consumption

## Research question 
How does the unanticipated government spending shock influence output, real exchange rate and consumption in the short run and in the long run?

## Motivation
Most economies have experienced significant shocks due to Covid Pandemic,resulting in a marked increase in government net debt-to-GDP ratios.  For instance,Australian's general government net debt-to-GDP ratio surged from 24.5\% in 2019 to 38.1 in 2021\%  by [@abs2021government], while the United States's ratio rose from 106.1\% to 121.1\% by [@fed2023federal]. 


There has been considerable research on the consequences of government spending shocks on output, consumption, and other crucial macroeconomic factors. Economic theory suggests that positive shocks result in increased output and consumption. However, there has been less emphasis on the economy's external sector, including real exchange rates, imports, and exports. By employing the SVARs model to identify government spending shocks and investigating their connection with these variables, policymakers can enhance the formulation and execution of fiscal and monetary policies in response to unanticipated government spending shocks.

# 2. Data and their properties

## Data 

For this study, quarterly data will be utilized for estimation purposes, as it is more reasonable to assume that government spending can respond within a given period. The primary focus of this research will be on the Australian economy, allowing for an in-depth analysis of its reaction to government spending shocks. It is important to note that the findings may not necessarily be applicable to other countries due to their distinct institutional features and economic attributes. Future research could extend the model to other nations in order to gain a broader understanding of cross-country variations in response to government spending shocks.

Initially, I will load the packages that enable direct data downloads from the Reserve Bank of Australia [@rba2023statistics] and the Federal Reserve Bank of St. Louis [@FRED].

```{r, echo=TRUE}
library(readabs)
library(readrba)
library(tseries)
library(ggplot2)
library(cowplot)
library(dplyr)
library(zoo)
library(tidyverse)
library(fredr)
library(urca)
library(xts)
```



## Variables

### Consumption
The dataset contains information on household final consumption expenditure, which is measured in millions of dollars and recorded quarterly, with adjustments for seasonal variations. The plot, however, reveals that the data is non-stationary, with the mean value changing over time. This is a common characteristic of macroeconomic variables. As a result, I also look at the consumption growth data instead, which measures the year-ended household consumption growth and displays a decline in 2020 due to the COVID-19 pandemic. The mean value of consumption growth is 3.41%, indicating that the growth rate fluctuates around this value and is stationary over time.

In the model, the original consumption variable is log-transformed to reduce the scale and conform to the assumption of normality.

```{r}
# Data extraction and cleaning
# Consumption and consumption growhth
consumption.dl   <- read_rba(series_id = "GGDPECCVPSH")
consumption <- to.quarterly(xts(consumption.dl$value, consumption.dl$date), OHLC = FALSE)
consumption_growth <- 100*diff(log(consumption))

# real GDP
realGDP.dl   <- read_rba(series_id = "GGDPCVGDP")
realGDP <- to.quarterly(xts(realGDP.dl$value, consumption.dl$date), OHLC = FALSE)
realGDP_growth <- 100*diff(log(realGDP))

# nominal GDP, seasonally adjusted (in case you decide to use this instead)
nomGDP.dl <- read_abs(series_id = "A2454486X")
nomGDP <- to.quarterly(xts(nomGDP.dl$value, consumption.dl$date), OHLC = FALSE)
nomGDP_growth <- 100*diff(log(nomGDP))



# Trade balance
imports.dl <- read_abs(series_id = "A2454505V")
imports <- to.quarterly(xts(imports.dl$value, consumption.dl$date), OHLC = FALSE)

exports.dl <- read_abs(series_id = "A2454510L") 
exports <- to.quarterly(xts(exports.dl$value, consumption.dl$date), OHLC = FALSE)

# Inflation
CPI.dl <- read_abs(series_id = "A2325846C")
CPI <- to.quarterly(xts(CPI.dl[45:(nrow(CPI.dl)-1),]$value, consumption.dl$date), OHLC = FALSE)

CPI_inflation.dl <- read_rba(series_id = "GCPIAGQP")
CPI_inflation <- to.quarterly(xts(CPI_inflation.dl[149:(nrow(CPI_inflation.dl)-1),]$value, consumption.dl$date), OHLC = FALSE)

# real exchange rate (TWI)
realTWI.dl   <- read_rba(series_id = "FRERTWI")
realTWI <- to.quarterly(xts(realTWI.dl[-nrow(realTWI.dl),]$value,consumption.dl[44:nrow(consumption.dl),]$date), OHLC = FALSE) 
#realTWI <- to.quarterly(xts(realTWI.dl$value,CPI.dl[88:nrow(CPI.dl),]$date), OHLC = FALSE)

#realTWI <- to.quarterly(xts(realTWI.dl$value,exports.dl$date), OHLC = FALSE)

# M3
M3.dl   <- read_rba(series_id = "DMAM3N")
M3 <- to.quarterly(xts(M3.dl$value, M3.dl$date), 
                         OHLC = FALSE)

# Government spending, seasonally adjusted
pubcons.dl <- read_abs(series_id = "A2304036K")
pubcons <- to.quarterly(xts(pubcons.dl$value, consumption.dl$date),
                         OHLC = FALSE)

pubinv.dl <- read_abs(series_id = "A2304064V")
pubinv <- to.quarterly(xts(pubinv.dl$value, consumption.dl$date), 
                         OHLC = FALSE)

gov_spend <- pubcons + pubinv
gov_spend_growth <- 100*diff(log(gov_spend))

# matrix of endogenous variables 
# df <-  merge(consumption, realGDP, nomGDP,  realTWI, imports,exports,CPI)
df <-  merge(consumption, realGDP, nomGDP,  realTWI, imports,exports,CPI)
df2 <- merge(df,realTWI, by = "Date")
df$M3 <- as.numeric(M3[-nrow(M3)])
df$gov_spend <- as.numeric(gov_spend)
df <- na.omit(df)
df$Date <- as.vector(index(df))





# transformed in log terms
log_df <- log(df)
log_df$Date <- as.vector(index(log_df))

#growth rates including inflation 
growth_df <- na.omit(merge(consumption_growth, realGDP_growth, nomGDP_growth, CPI_inflation, 
                           gov_spend_growth))
growth_df$Date <- as.vector(index(growth_df))

# set date for 
```



```{r}
# Consumption levels and growth plot
plot1<- ggplot(data = log_df, aes(x = Date, y =consumption)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " Household Consumption (log)", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")
plot2<- ggplot(data = growth_df, aes(x = Date, y =consumption_growth)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " Household Consumption Growth", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

plot <- plot_grid(plot1, plot2,  ncol = 1, align = "v")
print(plot)

```


### GDP

The real GDP is measured in million dollars, and the plot of this data suggests that it is non-stationary due to its increasing trend. To address this, I transformed the original variable using the lag() function in R, resulting in the GDP percentage change.

When examining the plot of the GDP percentage change, it appears to be more stationary over time. However, the data fluctuates significantly during the COVID period. In a later section, I also run ACF and PACF tests, which suggest that I should keep the original variable.
```{r}
# GDP levels and growth plot

plot2<- ggplot(data = log_df, aes(x = Date, y =realGDP)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " GDP (log)", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")
plot3<- ggplot(data = growth_df, aes(x = Date, y =realGDP_growth)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " GDP percentage change", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

plot <- plot_grid(plot2, plot3,  ncol = 1, align = "v")
print(plot)

```
### Exchange rate

The real exchange rate data is sourced from the Reserve Bank of Australia (RBA) and is provided on a quarterly basis. RBA uses the Australian dollar trade-weighted index as a measure of the real exchange rate. This index represents the price of the Australian dollar in terms of a group of foreign currencies, based on their share of trade with Australia.
```{r }


# TWI 

plot5<- ggplot(data = df, aes(x = Date, y =realTWI)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " Real exchange rate (TWI)", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

print(plot5)
```






Additionally, I also investigate the nominal exchange rate variable. I download the AUD/USD exchange rate, as the US dollar is widely accepted as an international currency. (Note: The data obtained using the package may not exactly match the description on the website.) However, since the nominal exchange rate may be influenced by various factors and due to data availability constraints, this research will focus exclusively on the real interest rate (TWI).



### Trade balance

The trade balance data is calculated by taking the difference between exports and imports.


```{r}

plot6<- ggplot(data = log_df, aes(x = Date)) +
  geom_line(aes(y = exports-imports), color = "steelblue", size = 0.8) +
  #geom_line(aes(y = imports), color = "firebrick", size = 0.8) +
  labs(title = " Trade Balance (log)", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

print(plot6)

```





### government spending data
I will keep the log transformation of the original variable.
```{r}
plot7<- ggplot(data = log_df, aes(x = Date, y =gov_spend)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " Government Spending", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

plot8<- ggplot(data = growth_df, aes(x = Date, y =gov_spend_growth)) +
  geom_line(color = "steelblue", size = 0.8) +
  labs(title = " Government Spending percentage change", x = "Period", y = "Index") +
  theme_bw() +
  theme(plot.title = element_text(size = 16, hjust = 0.5, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.position = "none")

gov_plot <- plot_grid(plot7, plot8,  ncol = 1, align = "v")
print(gov_plot)

```
    
I also run the ADF test for this variable, and with a p-value of 0.5, we cannot reject the null hypothesis, indicating that the government spending data is expected to be non-stationary. For completeness, I also plot the ACF (autocorrelation function) and PACF (partial autocorrelation function). As shown in the ACF, there is a slow and gradual decay, suggesting that an autoregressive process might be suitable for the data. The PACF results also support using an AR model because the plot has a sharp cut-off.

```{r}
# adf.test(gov_spending_australia$log_gov)
# test1 = acf(gov_spending_australia$log_gov)
# test2 = pacf(gov_spending_australia$log_gov)
```


## preliminary Data Analysis

In this section, I will present a table of the ADF test results for the remaining variables for completeness. As stated in the previous section, I will retain the log transformation of the original variable in my research. Additionally, the PACF and ACF tests suggest using an autoregression model.

### ADF test
 

```{r}
library(tidyverse)
library(urca)
library(xts)

# Convert the 'xts' object to a 'data.frame'
df_data_frame <- as.data.frame(df)[, -which(colnames(df) == "Date")]



# Perform the ADF test on each variable and extract the test statistic and p-value

# this procedure below is nicely coded! But using 1 lag for all the variables is not good. Better too high a lag number than too small. Stationarity of the TWI is most likely only the effect of too few lags used.
adf_summary <- map_df(df_data_frame , function(x) {
  adf_test <- ur.df(x, type = "none", lags = 1)
  adf_test_summary <- summary(adf_test)
  tibble(
    Test_statistic = adf_test_summary@teststat[1, 1],
    Critical_value= adf_test_summary@cval[1, 1]
  )
}, .id = "Variable")

# Perform the test for the first differences to determine the integration order and report in one table please




# Add variable names to the summary table
adf_summary$Variable <- colnames(df_data_frame )

# Display the ADF test summary table
knitr::kable(adf_summary, digits = 3)

```

As anticipated, macroeconomic data is typically non-stationary. The only exception in this case is the real exchange rate, which is stationary.

### PACF and ACF test

```{r}
nrow <- 3
ncol <- 3

# Set up the combined plot grid
par(mfrow = c(nrow, ncol))

# Run the ACF and PACF functions for each variable and display the plots
for (i in seq_along(df_data_frame )) {
  variable_name <- colnames(df_data_frame )[i]

  # ACF plot
  acf(df_data_frame [[i]], main = paste("ACF of", variable_name))
}

# Reset the graphical parameters to default
par(mfrow = c(nrow, ncol))

# PACF plot
for (i in seq_along(df_data_frame )) {
  variable_name <- colnames(df_data_frame )[i]

  # PACF plot
  pacf(df_data_frame [[i]], main = paste("PACF of", variable_name))
}



```
# 3. The model 



## Model Specification 

### Structural Form (SF)
The structural model is specified as follows:
$$\begin{align}
B_0y_t &= b_0 + B_1 y_{t-1} + \dots + B_p y_{t-p} + u_t\\
u_{t}| Y_{t-1} &\sim _{iid} ( 0, I_N)
\end{align}$$

### Reduced Form (RF)
Then the empirical model for this study is a structural vector autoregression of the reduced form representation:

$$\begin{align}
y_t &= \mu_0 + A_1 y_{t-1} + \dots + A_p y_{t-p} + \varepsilon_t\\
\text{where }B_0^{-1}u_t &= \varepsilon_t| Y_{t-1} \sim _{iid} ( 0, \Sigma)\\
\Sigma &= B_0^{-1}B_0^{-1'}
\end{align}$$

Where:

$$y_t=\begin{pmatrix}  govspend_t &= \text{government spending}
\\ consump_t  &= \text{consumption}
\\ realGDP_t  &= \text{real GDP}
\\ TWI_t  &= \text{real exchange rate (trade-weighted index)}
\\ CPI_t  &= \text{consumer price index}
\\ export_t  &= \text{exports}
\\ imports_t  &= \text{imports}
\\ M3_t  &= \text{M3 money supply}
\end{pmatrix}$$

$\varepsilon_t$ is a vector of the structural shocks at time t.

Assumptions regarding the model's error terms:
$\varepsilon_t |Y_{t-1}  \sim iid(0_N, Î£)$

## Impusle response function and Forecast error variance decomposition

The research project aims to model the effect of government spending shocks on output, real exchange rate, and consumption. The SVAR model specified above captures the dynamic relationships among the endogenous variables. To answer the research questions, I will use the SVAR model to estimate the impulse response functions (IRFs) and forecast error variance decomposition (FEVDs) for each endogenous variable. With IRFs, I will be able to observe the dynamic response of each variable, while the FEVDs will quantify the portions of the forecast error variance of each variable attributable to the shocks this paper aims to identify.


## Relevant economic context
I would expect the IRF for government spending to initially increase in response to the government spending shock and then decrease to the steady state. Consumption and GDP will also increase, but on a smaller scale compared to government spending. I am uncertain about the real exchange rate. Data shows that the real exchange rate will increase upon the shock and continue to rise after the shock.


# 4. Modelling Framework

## Basic Model
First, I re-write the RF of the model as the following matrix notation:
$$\begin{align*}  Y = XA + E \\ \text{where} E|X \sim MN_{T \times N}(0_{T \times N},\Sigma,I_T)  \end{align*}$$

Let $ L(A, \Sigma | Y, X)$ be the likelihood function given by:


$$
L(A, \Sigma | Y, X) \propto \det(\Sigma)^{-\frac{T}{2}} \exp \left\{-\frac{1}{2} \text{tr} \left[ \Sigma^{-1}(Y-XA)'(Y-XA) \right] \right\}
$$


We can further simplify it as:

$$
L(A, \Sigma | Y, X) \propto \det(\Sigma)^{-\frac{T}{2}} \exp \left\{-\frac{1}{2} \text{tr} \left[ \Sigma^{-1}(A-\hat{A})'X'X(A-\hat{A}) \right] \right\} \exp \left\{-\frac{1}{2} \text{tr} \left[\Sigma^{-1}(Y-X\hat{A})'(Y-X\hat{A}) \right] \right\}
$$

Let $L(A, \Sigma | Y, X)$ be the likelihood function given by:

$$
L(A, \Sigma | Y, X) \propto \det(\Sigma)^{-\frac{T}{2}} \exp \left\{-\frac{1}{2} \text{tr} \left[ \Sigma^{-1}(Y-XA)'(Y-XA) \right] \right\}
$$

We can further simplify it as:

$$
L(A, \Sigma | Y, X) \propto \det(\Sigma)^{-\frac{T}{2}} \exp \left\{-\frac{1}{2} \text{tr} \left[ \Sigma^{-1}(A-\hat{A})'X'X(A-\hat{A}) \right] \right\} \exp \left\{-\frac{1}{2} \text{tr} \left[\Sigma^{-1}(Y-X\hat{A})'(Y-X\hat{A}) \right] \right\}
$$




From Maximum Likelihood Estimation,

$$
\hat{A} = (X'X)^{-1}X'Y
$$

$$
\hat{\Sigma} = \frac{1}{T} (Y-X \hat{A})'(Y-X \hat{A})
$$


The prior distribution is given by:

$$
p(A, \Sigma) = p(A|\Sigma) \cdot p(\Sigma)
$$

where:

$$
A|\Sigma \sim MN_{K \times N} (\underline{A}, \Sigma , \underline{V})
$$

$$
\Sigma \sim IW_{N}(\underline{S},\underline{\nu})
$$

The parameters are defined as follows:

$$
\underline{A} = \begin{bmatrix} 0_{N \times 1} \\ I_N \\ 0_{N \times (p-1)N} \end{bmatrix}
$$

$$
\text{Var}[vec(A)] = \Sigma \otimes \underline{V}
$$

$$
\underline{V} = \text{diag}([\kappa_2 \quad \kappa_1 (p^{-2} \otimes I_N)])
$$

$$
p = [1,2,...,p]
$$


The full conditional posterior is given by:

$$
p(A,\Sigma|Y,X) = p(A|Y,X,\Sigma) \cdot p(\Sigma|Y,X)
$$

where:

$$
p(A|Y,X,\Sigma) = MN_{K \times N}(\bar{A}, \Sigma, \bar{V})
$$

$$
p(\Sigma | Y, X) = IW_N(\bar{S},\bar{\nu})
$$

We can derive the full conditional posterior as follows:

$$
P(A,\Sigma|Y,X) \propto L(A,\Sigma|Y,X) \cdot p(A,\Sigma)
$$

$$
\propto L(A,\Sigma|Y,X) \cdot p(A|\Sigma) \cdot p(\Sigma)
$$

$$
\propto \det(\Sigma)^{-\frac{T}{2}} \times \exp \left\{-\frac{1}{2} \text{tr} \left[ \Sigma^{-1}(A-\hat{A})' X'X (A-\hat{A})\right] \right\}
$$

$$
\times \exp\left\{-\frac{1}{2}\text{tr} \left[ \Sigma^{-1}(Y-X\hat{A})'(Y-X\hat{A}) \right] \right\}
$$

$$
\times \det(\Sigma)^{-\frac{N+K+\underline{\nu}+1}{2}}
$$

$$
\times \exp\left\{-\frac{1}{2}\text{tr} \left[ \Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A}) \right] \right\}
$$

$$
\times \exp \left\{ -\frac{1}{2}\text{tr} \left[ \Sigma^{-1} \underline{S} \right] \right\}
$$

Simplifying further, we have:

$$
p(A,\Sigma|Y,X) \propto \det{(\Sigma)}^{-\frac{T+N+K+\underline{\nu}+1}{2}} \times \exp \left\{-\frac{1}{2}\text{tr} \left[ \Sigma^{-1} \left[(A-\hat{A})^{'}X'X(A-\hat{A})+(A-\underline{A})^{'} \underline{V}^{-1}(A-\underline{A}) + (Y-X\hat{A})^{'}(Y-X\hat{A})+\underline{S}  \right]\right] \right\}
$$

$$
\propto \det{(\Sigma)}^{-\frac{T+N+K+\underline{\nu}+1}{2}} \times \exp\left\{ -\frac{1}{2}\text{tr} \left[ \Sigma^{-1} \left[ (A-\bar{A})^{'} \bar{V}^{-1} (A-\bar{A})+\underline{S} +Y^{'}Y + \underline{A}^{'} \underline{V}^{-1}\underline{A} -\bar{A}^{'} \bar{V}^{-1}\bar{A}\right]\right]\right\}
$$

where:

$$
\bar{V} = (X^{'}X+ \underline{V}^{-1})^{-1}
$$

$$
\bar{A} = \bar{V}(X^{'}Y+\underline{V}^{-1} \underline{A})
$$

$$
\bar{\nu} = T + \underline{\nu}
$$

$$
\bar{S} = \underline{S} + Y^{'}Y +  A^{'}\underline{V}^{-1}\underline{A} - \bar{A}^{'}\bar{V}^{-1}\bar{A}
$$

Based on the derivation, the posterior function is 

```{r, echo=TRUE}

## Function for drawing posterior distribution , based on lec 12
kappa.1 = 1

Posterior <- function(Y, X, p, N, S,kappa.1) {
  # MLE
  ############################################################
  A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
  Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)
  # round(A.hat,3)
  # round(Sigma.hat,3)
  # round(cov2cor(Sigma.hat),3)
  
  # prior distribution
  ############################################################
  kappa.1     = kappa.1
  kappa.2     = 100
  kappa.3     = 1
  A.prior     = matrix(0,nrow(A.hat),ncol(A.hat))
  A.prior[2:(N+1),] = kappa.3*diag(N)
  V.prior     = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
  S.prior     = diag(diag(Sigma.hat))
  nu.prior    = N+1
  
  # normal-inverse Wishard posterior parameters
  ############################################################
  V.bar.inv   = t(X)%*%X + diag(1/diag(V.prior))
  V.bar       = solve(V.bar.inv)
  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
  nu.bar      = nrow(Y) + nu.prior
  S.bar       = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
  S.bar.inv   = solve(S.bar)
  
  # posterior draws 
  ############################################################
  Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
  Sigma.posterior   = apply(Sigma.posterior,3,solve)
  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
  B.posterior       = array(NA,c(N,N,S))
  L                 = t(chol(V.bar))
  B1.posterior = array(NA,c(N,(1+N*p),S))
  
  for (s in 1:S){
    cholSigma.s     = chol(Sigma.posterior[,,s])
    B.posterior[,,s]= t(cholSigma.s)
    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%cholSigma.s
    B1.posterior[,,s] =  B.posterior[,,s]%*%t(A.posterior[,,s])
  }
  
  return(list(A.posterior = A.posterior, B.posterior = B.posterior, Sigma.posterior = Sigma.posterior,B1.posterior = B1.posterior))
  
}


```
The sign restriction algorithm is based on lecture algorithm 2. For current project, it only restricts the impulse response function at time 0.
```{r ,echo=TRUE}
### Impose sign restrictions based on Algorithm 2
# SignRestrictions <- function(sign.restrictions,N,S,p,A.posterior,B.posterior,B1.posterior,Sigma.posterior){

SignRestrictions <- function(sign.restrictions,posterior){
  # posterior -   a list - estimation outcome from function Posterior
  
  
  A.posterior   = posterior$A.posterior
  B.posterior = posterior$B.posterior
  B1.posterior = posterior$B1.posterior
  Sigma.posterior = posterior$Sigma.posterior
  
  S = dim(A.posterior)[3]
  N = dim(B.posterior)[1]
  p = (dim(B1.posterior)[2]-1)/N
   
  
  R1            = diag(sign.restrictions)
  B0.draws      = array(NA,c(N,N,S))
  B1.draws      = array(NA,c(N,(1+N*p),S))
  pb = txtProgressBar(min = 0, max = S, initial = 0)
for (s in 1:S){
  
  setTxtProgressBar(pb, s)
  
  B0.tilde <-B.posterior[,,s]
  B1.tilde <-  B1.posterior[,,s]
  A <- A.posterior[,,s]
  Sigma <- Sigma.posterior[,,s]
  
  sign.restrictions.do.not.hold = TRUE

  i=1
  
  while (sign.restrictions.do.not.hold){
    X           = matrix(rnorm(N*N),N,N)
    QR          = qr(X, tol = 1e-10)
    Q           = qr.Q(QR,complete=TRUE)
    R           = qr.R(QR,complete=TRUE)
    Q           = t(Q %*% diag(sign(diag(R))))
    B0          = Q%*%B0.tilde 
    B0.inv      = solve(B0) 
    check       = prod(R1 %*% B0.inv %*% diag(N)[,1] > 0) # Check reponse at time 0
    
    
    if (check==1){sign.restrictions.do.not.hold=FALSE}
    i=i+1
  }
  B1            = Q%*%B1.tilde 
  B0.draws[,,s] = B0
  B1.draws[,,s] = B1

}

  return (list(B0.draws = B0.draws,
               B1.draws = B1.draws,
               i        = i))
}
```





```{r}
# Posterios for basic model
#####################################################
# 
# p = 4 # time lagt0  
# N = 8
# S = 100
# 
# # Create Y and X
# y = ts(df[, !names(df) %in% c("Date","nomGDP")])
# Y = y[5:211,]
# X       = matrix(1,nrow(Y),1)
# for (i in 1:p){
#   X     = cbind(X,y[5:211-i,])
# }
# results <- Posterior(Y, X, p, N, S)
# 
# 
# # Sign.restriction######## 
# ############################################################
# set.seed(123456)
# sign.restrictions <- c(1,1,1,1,1,1,1,1)
# 
# 
# ################### Apply Sign Restriction ########################
# 
# Basic.Restriction = SignRestrictions(sign.restrictions,results)
# 
# B0.draws = Basic.Restriction$B0.draws
# B1.draws = Basic.Restriction$B1.draws
# 
# 
# ###############################################
# 
# 


```


## Extended model
The extended model adopts the narrative sign restriction in (@antolin-diaz2018narrative). In this extension, the focus is on imposing restrictions on the signs of the Structural Shocks. The concept revolves around constraining the sign of specific structural shocks during a particular time period, guided by the narrative information.

The posterior distribution is the same as the basic model. The difference is on the sign restriction. Based on the original sign restriction, the structural shocks for each period can be calculated by:

$$\begin{align*} u_t = B_0 y_t - B_1 y_{t-1} - .. - b_0 \end{align*}$$


Then we could put the restrictions on the sign of $u_t$.


```{r, echo=TRUE}
NarrativeSignRestrictions <- function(sign.restrictions,posterior,narrative.restrictions,Y,X){
  # posterior -   a list - estimation outcome from function Posterior
  
  
  A.posterior   = posterior$A.posterior
  B.posterior = posterior$B.posterior
  B1.posterior = posterior$B1.posterior
  Sigma.posterior = posterior$Sigma.posterior
  YY = Y
  XX = X
  
  S = dim(A.posterior)[3]
  N = dim(B.posterior)[1]
  p = (dim(B1.posterior)[2]-1)/N
  
  
  R1            = diag(sign.restrictions)
  B0.draws      = array(NA,c(N,N,S))
  B1.draws      = array(NA,c(N,(1+N*p),S))
  pb = txtProgressBar(min = 0, max = S, initial = 0)
  for (s in 1:S){
    
    setTxtProgressBar(pb, s)
    
    B0.tilde <-B.posterior[,,s]
    B1.tilde <-  B1.posterior[,,s]
    A <- A.posterior[,,s]
    Sigma <- Sigma.posterior[,,s]
    
    sign.restrictions.do.not.hold = TRUE
    narrative.restriction.do.not.hold = TRUE
    i=1
    
    while (sign.restrictions.do.not.hold){
      X           = matrix(rnorm(N*N),N,N)
      QR          = qr(X, tol = 1e-10)
      Q           = qr.Q(QR,complete=TRUE)
      R           = qr.R(QR,complete=TRUE)
      Q           = t(Q %*% diag(sign(diag(R))))
      B0          = Q%*%B0.tilde 
      B0.inv      = solve(B0) 
      B1          = Q%*%B1.tilde 
      u = YY %*% t(B0) - XX %*% t(B1)
      u= u[,1]
      check       = prod(R1 %*% B0.inv %*% diag(N)[,1] > 0  ) # Check reponse at time 0
      check_narrative = prod(sign(u[narrative.restrictions]) > 0)
      
      if (check == 1 && check_narrative == 1) {
        sign.restrictions.do.not.hold = FALSE
      }
      i = i + 1
      B0.draws[, , s] = B0
      B1.draws[, , s] = B1
    }
    
    close(pb)
    
  }
  
  return (list(B0.draws = B0.draws,
               B1.draws = B1.draws,
               i        = i))
}

```

## Simulations 
This section aims to evaluate the code by generating artificial data consisting of 1000 observations simulated from a bivariate Gaussian random walk process. The covariance matrix of the process is set to be the 2x2 identity matrix. 

```{r}
### Proof that your model can replicate the true parameters of the data-generating process.


# Set parameters
n_obs = 1000
p <- 1
N <- 2
S <- 50000

# 1. Generate artificial data
set.seed(2023) # for reproducibility
cov_matrix <- diag(N)
mean_vector <- rep(0, N)

# Simulate bi-variate Gaussian random walk
RW1 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)
RW2 <- arima.sim(model= list(order = c(0, 1, 0)), n=1000, mean=0, sd=1)
y = cbind(RW1,RW2) 

y <- ts(y)

# 2. Estimate the model
# Create Y and X
Y <- y[(p + 1):n_obs, ]
X <- matrix(1, nrow(Y), 1)

for (i in 1:p) {
  X <- cbind(X, y[(p + 1 - i):(n_obs - i), ])
}
plot(y)


```
### Basic Model
I first test my sign Restriction function with the simulated data. The sign restriction here is both positive. 
| Restriction |  + | + |
The A and $\Sigma$ is presented below, suggesting the basic model is working.

The first row of A is close to zero, implying a zero constant and the matrix is close to identity matrix.








```{r, echo=TRUE}
posterior <- Posterior(Y, X, p, N, S,kappa.1)



################### Apply Sign Restriction ########################

sign.restrictions = c(1,1)
Test.Restriction = SignRestrictions(sign.restrictions,posterior)

B0.draws = Test.Restriction$B0.draws
B1.draws = Test.Restriction$B1.draws


###############################################
A.check <- array(NA,c(N+1,N,S))
S.check <- array(NA,c(N,N,S))

for (s in 1:S){
  # convert Bo into Sigma 
  S.check[,,s] <- B0.draws[,,s] %*% t(B0.draws[,,s])
  A.check[,,s] <- t(B1.draws[,,s]) %*% B0.draws[,,s]
}
Acheck=round(apply(A.check,1:2,mean),4)
Scheck =round(apply(S.check,1:2,mean),4)

Acheck
Scheck
```

### Extended model
For this section, I assume the the sign of the structural shocks for period period 65 to period 67 is negative, which is also consistent with the original sign restriction. The parameter values for A and $\sigma$ suggests the function is working well.



```{r, echo=TRUE}
######## Narrative sign 
narrative.restrictions = c(65:67)

Narrative.Restriction = NarrativeSignRestrictions(sign.restrictions,posterior,narrative.restrictions,Y,X)

B0.draws = Narrative.Restriction$B0.draws
B1.draws = Narrative.Restriction$B1.draws


###############################################
AN.check <- array(NA,c(N+1,N,S))
SN.check <- array(NA,c(N,N,S))



for (s in 1:S){
  # convert Bo into Sigma 
  SN.check[,,s] <- B0.draws[,,s] %*% t(B0.draws[,,s])
  AN.check[,,s] <- t(B1.draws[,,s]) %*% B0.draws[,,s]
}

AN = round(apply(A.check,1:2,mean),4)
SN = round(apply(S.check,1:2,mean),4)

AN
SN
```

```{r example}
#narrative_restrictions <- matrix(NA, nrow = length(df$Date), ncol = 8)

# Government Spending Shock
#narrative_restrictions[c(50, 150), 1] <- 1  # Positive shock at episodes 50 and 150
#narrative_restrictions[100, 1] <- -1        # Negative shock at episode 100

# Apply NarrativeRestrictions function
#test = NarrativeRestrictions(sign.restrictions, N, S, p, Basic_A.posterior, Basic_B.posterior, Basic_B1.posterior, Basic_Sigma.posterior, narrative_restrictions)
```




# 5. Empirical Estimation

Sign Restrictions are taken as the following:

1. Government spending: A positive government spending shock increases government spending (govspend).

2. Consumption:  Generally, a positive government spending shock could potentially increase consumption. This is due to the multiplier effect. As the government spends more, this increases income for businesses and households, which can then lead to higher consumption. 

3. Real GDP: A positive government spending shock is typically expected to increase real GDP, at least in the short term. Government spending is a component of GDP (which is the sum of consumption, investment, government spending, and net exports). Therefore, if government spending increases, all else being equal, real GDP should also increase.

4. Real exchange rate: Generally, if the increase in government spending leads to higher interest rates, it could appreciate the real exchange rate as it attracts foreign investors seeking higher returns.

5. Consumer price index: By @jorgensen2022inflation, prices do not increase in response to a positive government spending shock. 

6. M3 money supply: Since the government financed its spending through borrowing, this could increase the money supply.

|                     |  Sign   |
|---------------------|---------|
| Government Spending | 1       |
| Consumption         | 1       |
| Real GDP            | 1       |
| Real Exchange Rate  | 1       |
| CPI                 | -1      |
| M3                  | 1       |
| Imports             | 1       |
| Exports             | 1       |

## Narrative information
Information about the the government spending shock.

## Impulse Response Function

```{r, echo=FALSE}
library(HDInterval)
set.seed(123456)
########IRF
p = 5 # time lagt0
N = 8
S = 1000

# Create Y and X



######### spending,consumption,realGDP as log form ##################
# dff = df[, names(df) %in% c("consumption","gov_spend","realGDP","M3","CPI","imports","exports")]
# dff = df[, names(df) %in% c("consumption","gov_spend","realGDP","M3","imports","exports")]
# dff = log(dff)
# # dff$realTWI = df$realTWI
# dff$CPI = df$CPI
# y = ts(dff)

# y = ts(df[, !names(df) %in% c("Date","nomGDP","imports","exports")])

# y = ts(df[, !names(df) %in% c("Date","nomGDP","realTWI")])
y = ts(df[, !names(df) %in% c("Date","nomGDP")])
y = log(y)

Y = y[(p+1):211,]

X       = matrix(1,nrow(Y),1)

for (i in 1:p){
  X     = cbind(X,y[(p+1):211-i,])
}

results = Posterior(Y,X,p,N,S,1)
Sign_restritions = SignRestrictions(sign.restrictions = c(1,1,1,-1,1,-1,1,1), results)



##################### Results from the Sign_restriction ###################

B0.draws = Sign_restritions$B0.draws
B1.draws = Sign_restritions$B1.draws



##############################################
A.posterior <- array(NA,c(N*p+1,N,S))
B.posterior       = array(NA,c(N,N,S))
S.check <- array(NA,c(N,N,S))

for (s in 1:S){
  # convert to into A and B
  B  = solve(B0.draws[,,s])
  # S.check[,,s] <- B0.draws[,,s] %*% t(B0.draws[,,s])
  # cholSigma.s     = chol(S.check[,,s])
  # B.posterior[,,s]= t(cholSigma.s)
  B.posterior[,,s] = B
  A.posterior[,,s] <- t(B1.draws[,,s]) %*% B0.draws[,,s]
}

############################### From the porsterior distribution#########
# A.posterior = results$A.posterior
# B.posterior = results$B.posterior


########https://www.sciencedirect.com/science/article/pii/S0014292121002634#####


h = 8



IRF.posterior     = array(NA,c(N,N,h+1,S))
IRF.inf.posterior = array(NA,c(N,N,S))
FEVD.posterior    = array(NA,c(N,N,h+1,S))
J                 = cbind(diag(N),matrix(0,N,N*(p-1)))

for (s in 1:S){
  A.bold          = rbind(t(A.posterior[2:(1+N*p),,s]),cbind(diag(N*(p-1)),matrix(0,N*(p-1),N)))
  IRF.inf.posterior[,,s]          = J %*% solve(diag(N*p)-A.bold) %*% t(J) %*% B.posterior[,,s]
  
  A.bold.power    = A.bold
  for (i in 1:(h+1)){
    if (i==1){
      IRF.posterior[,,i,s]        = B.posterior[,,s]
    } else {
      IRF.posterior[,,i,s]        = J %*% A.bold.power %*% t(J) %*% IRF.posterior[,,i-1,s]
      A.bold.power                = A.bold.power %*% A.bold
    }
    for (n in 1:N){
      for (nn in 1:N){
        FEVD.posterior[n,nn,i,s]  = sum(IRF.posterior[n,nn,1:i,s]^2)
      }
    }
    FEVD.posterior[,,i,s]         = diag(1/apply(FEVD.posterior[,,i,s],1,sum))%*%FEVD.posterior[,,i,s]
  }
}
FEVD.posterior    = 100*FEVD.posterior


# save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k002.RData")
save(IRF.posterior,IRF.inf.posterior, FEVD.posterior, file="irf-fevd-k1.RData")

# Define colors
mcxs1  = "#05386B"
mcxs2  = "#379683"
mcxs3  = "#5CDB95"
mcxs4  = "#8EE4AF"
mcxs5  = "#EDF5E1"
purple = "#b02442"
mcxs1.rgb   = col2rgb(mcxs1)
mcxs1.shade1= rgb(mcxs1.rgb[1],mcxs1.rgb[2],mcxs1.rgb[3], alpha=120, maxColorValue=255)
mcxs2.rgb   = col2rgb(mcxs2)
mcxs2.shade1= rgb(mcxs2.rgb[1],mcxs2.rgb[2],mcxs2.rgb[3], alpha=120, maxColorValue=255)

# Plots of responses to domestic monetary policy shock
############################################################
load("irf-fevd-k1.RData")
IRFs.k1           = apply(IRF.posterior[,1,,],1:2,mean) 

######1st shock is government  spending shock

IRFs.inf.k1       = apply(IRF.inf.posterior[,1,],1,mean)
rownames(IRFs.k1) = colnames(Y)

IRFs.k1.hdi    = apply(IRF.posterior[,1,,],1:2,hdi, credMass=0.68)
hh          = 1:9


par(mfrow=c(3,2), mar=c(4,4.5,2,2),cex.axis=1.5, cex.lab=1.5)
for (n in 1:6){
  ylims     = range(IRFs.k1[n,hh],IRFs.k1.hdi[,n,hh])
  plot(hh,IRFs.k1[n,hh], type="l", ylim=ylims, axes=FALSE, xlab="", ylab=rownames(IRFs.k1)[n])
  if (n==5 | n==6){
    axis(1,c(1,2,5,9),c("","1 quarter","1 year","2 years"))
  } else {
    axis(1,c(1,2,5,9),c("","","",""))
  }
  axis(2,c(ylims[1],0,ylims[2]),round(c(ylims[1],0,ylims[2]),3))
  polygon(c(hh,(h+1):1), c(IRFs.k1.hdi[1,n,hh],IRFs.k1.hdi[2,n,(h+1):1]), col=mcxs1.shade1,border=mcxs1.shade1)
  abline(h=0)
  lines(hh, IRFs.k1[n,hh],lwd=2,col=mcxs1)
}

```
## Forecast Varaince Decomposition

```{r}
# Plots of FEVD of Australian rgdp and p

############################################################

hh <- 1:(h + 1)
fevd.au.rgdp <- apply(FEVD.posterior[2,,,], 1:2, mean)
fevd.au.rgdp <- rbind(rep(0, h + 1), apply(fevd.au.rgdp, 2, cumsum))

fevd.realTWI <- apply(FEVD.posterior[3,,,], 1:2, mean)
fevd.realTWI <- rbind(rep(0, h + 1), apply(fevd.realTWI, 2, cumsum))

colors <- c("deepskyblue1","deepskyblue2","deepskyblue","deepskyblue3","deepskyblue4","dodgerblue",
            "maroon1","maroon","maroon2","magenta","maroon3","maroon4")



# Set up the layout for two plots side by side
# par(mfrow = c(3, 2), mar = rep(4, 4), cex.axis = 1, cex.lab = 0.8)

# Plotting fevd-au-gdp-k1

plot(hh, fevd.au.rgdp[1,], type = "n", ylim = c(0, 100), axes = FALSE, xlab = "", ylab = "")
axis(1, hh, c("", "1 quarter", "", "", "1 year", "", "", "", "2 years"))
axis(2, c(0, 50, 100), c("", "FEVD[au.rgdp]", ""))
for (n in 1:N) {
  polygon(c(hh, (h + 1):1), c(fevd.au.rgdp[n, hh], fevd.au.rgdp[n + 1, (h + 1):1]), col = colors[n], border = colors[n])
}
axis(4, (0.5 * (fevd.au.rgdp[1:n, 9] + fevd.au.rgdp[2:n+1, 9]))[c(3, 8, 10)], c("us.mps", "", "au.mps"))

# Plotting fevd-au-p-k1
plot(hh, fevd.realTWI[1,], type = "n", ylim = c(0, 100), axes = FALSE, xlab = "", ylab = "")
axis(1, hh, c("", "1 quarter", "", "", "1 year", "", "", "", "2 years"))
axis(2, c(0, 50, 100), c("", "FEVD[realTWI]", ""))
for (n in 1:N) {
  polygon(c(hh, (h + 1):1), c(fevd.realTWI[n, hh], fevd.realTWI[n + 1, (h + 1):1]), col = colors[n], border = colors[n])
}
axis(4, (0.5 * (fevd.realTWI[1:n, 9] + fevd.realTWI[2:n+1, 9]))[c(3, 10)], c("us.mps", "au.mps"))



```

## References {.unnumbered}



